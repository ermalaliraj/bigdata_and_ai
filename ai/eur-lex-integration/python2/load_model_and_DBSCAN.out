Loading  ./model/lda_eu_regulations_model.dat
Loading  ./model/lda_eu_regulations_model_corpus.dat
Loaded Regulations model and corpus data.

Total topics 100. Printing first 5:
['digital', 'right', 'term', 'long', 'capacity']
['datum', 'cabinet', 'blast', 'chill', 'celsius']
['datum', 'personal', 'processing', 'subject', 'authority']
['dioxide', 'titanium', 'product', 'cosmetic', 'use']
['accordance', 'animal', 'celsius', 'blast', 'chill']

Checking 100 topics loaded from the model
Total words in topics  500
Re-build corpus string concatenating all 1860 words sorted by words.index
Generated 229 tokens
word_vectors from tokens (229, 96)

Perform DBSCAN clustering from vector array or distance matrix. :-
DBSCAN labels with the word_vectors:
 [-1 -1 -1  0  0  0  0  0 -1 -1  0 -1  0  0  0  0  0 -1 -1  0  0  0  0  0
 -1  0  0  0  0  0  0  0  0 -1 -1 -1 -1  0  0  0  0 -1 -1 -1 -1 -1 -1  0
  0  0  0  0  0 -1 -1 -1 -1 -1  0  0  0  0 -1 -1 -1 -1 -1 -1 -1 -1 -1  0
 -1  0 -1 -1 -1  0 -1  0  0  0 -1 -1 -1  0  0  0  0  0  0  0  0  0  0 -1
  0 -1  0  0  0  0  0  0  0  0  0  0 -1 -1  0  0 -1 -1 -1 -1 -1  0 -1  0
  0  0 -1 -1 -1 -1 -1  0  0 -1  0  0  0 -1 -1 -1  0 -1 -1  0  0 -1 -1  0
  0  0  0  0 -1  0  0 -1 -1 -1  0  0 -1 -1 -1 -1  0 -1 -1 -1 -1  0  0  0
  0  0  0  0  0  0 -1 -1  0  0  0  0  0 -1 -1  0  0 -1 -1 -1 -1 -1 -1 -1
  0  0 -1  0  0 -1 -1 -1 -1  0 -1 -1  0  0 -1 -1 -1 -1 -1  0 -1 -1 -1  0
  0  0  0  0 -1  0  0 -1 -1 -1  0  0 -1]

test_tokens:  glandless international technology program
test_vectors from test_tokens[4x9] instead of 229x96
 [[-0.32610622 -0.41542953 -0.6061435  -0.540838    0.1473784 ]
 [-0.5150769   1.1283845   0.14961365 -0.5590282  -0.23367202]
 [-0.3714217   1.6924269   0.12218499 -0.85527736  0.96168256]
 [-0.50023943  0.5739464   0.75071084  0.38207614 -0.2480401 ]]

Some predictions
Label for glandless:-1
Label for international:-1
Label for technology:-1
Label for program:-1